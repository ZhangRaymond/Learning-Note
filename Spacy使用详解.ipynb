{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先加载英文模型\n",
    "这里用的是 en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's word tokenize test for spacy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x15066f4fcf8>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x150683baca8>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x150683bad08>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm') # 默认en为 sm这版\n",
    "test_doc = nlp(u\"it's word tokenize test for spacy\")\n",
    "print(test_doc)\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n",
      "'s\n",
      "word\n",
      "tokenize\n",
      "test\n",
      "for\n",
      "spacy\n"
     ]
    }
   ],
   "source": [
    "for token in test_doc:\n",
    "\tprint(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 英文断句：\n",
    "test_doc.sents 将文档拆分成句子\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_doc = nlp(u'Natural language processing (NLP) deals with the application of computational models to text or speech data. Application areas within NLP include automatic (machine) translation between languages; dialogue systems, which allow a human to interact with a machine using natural language; and information extraction, where the goal is to transform unstructured text into structured (database) representations that can be searched and browsed in flexible ways. NLP technologies are having a dramatic impact on the way people interact with computers, on the way people interact with each other through the use of language, and on the way people access the vast amount of linguistic data now in electronic form. From a scientific viewpoint, NLP involves fundamental questions of how to structure formal models (for example statistical models) of natural language phenomena, and of how to design algorithms that implement these models.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) deals with the application of computational models to text or speech data.\n",
      "\n",
      "Application areas within NLP include automatic (machine) translation between languages; dialogue systems, which allow a human to interact with a machine using natural language; and information extraction, where the goal is to transform unstructured text into structured (database) representations that can be searched and browsed in flexible ways.\n",
      "\n",
      "NLP technologies are having a dramatic impact on the way people interact with computers, on the way people interact with each other through the use of language, and on the way people access the vast amount of linguistic data now in electronic form.\n",
      "\n",
      "From a scientific viewpoint, NLP involves fundamental questions of how to structure formal models (for example statistical models) of natural language phenomena, and of how to design algorithms that implement these models.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in test_doc.sents:\n",
    "    print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词干化（Lemmatize):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(you, '-PRON-', 561228191312463089)\n",
      "(are, 'be', 10382539506755952630)\n",
      "(best, 'good', 5711639017775284443)\n",
      "(., '.', 12646065887601541794)\n",
      "(it, '-PRON-', 561228191312463089)\n",
      "(is, 'be', 10382539506755952630)\n",
      "(lemmatize, 'lemmatize', 4507259281035238268)\n",
      "(test, 'test', 1618900948208871284)\n",
      "(for, 'for', 16037325823156266367)\n",
      "(spacy, 'spacy', 10639093010105930009)\n",
      "(., '.', 12646065887601541794)\n",
      "(I, '-PRON-', 561228191312463089)\n",
      "(love, 'love', 3702023516439754181)\n",
      "(these, 'these', 6459564349623679250)\n",
      "(books, 'book', 13814433107111459297)\n"
     ]
    }
   ],
   "source": [
    "test_doc = nlp(u\"you are best. it is lemmatize test for spacy. I love these books\")\n",
    "for token in test_doc:\n",
    "    print((token, token.lemma_, token.lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词性标注(POS Tagging):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(you, 'PRON', 95)\n",
      "(are, 'VERB', 100)\n",
      "(best, 'ADJ', 84)\n",
      "(., 'PUNCT', 97)\n",
      "(it, 'PRON', 95)\n",
      "(is, 'VERB', 100)\n",
      "(lemmatize, 'NOUN', 92)\n",
      "(test, 'NOUN', 92)\n",
      "(for, 'ADP', 85)\n",
      "(spacy, 'NOUN', 92)\n",
      "(., 'PUNCT', 97)\n",
      "(I, 'PRON', 95)\n",
      "(love, 'VERB', 100)\n",
      "(these, 'DET', 90)\n",
      "(books, 'NOUN', 92)\n"
     ]
    }
   ],
   "source": [
    "for token in test_doc:\n",
    "    print((token, token.pos_, token.pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 命名实体识别（NER）：\n",
    "test_doc.ents 表示命名实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Rami Eid, 'PERSON', 380)\n",
      "(Stony Brook University, 'ORG', 383)\n",
      "(New York, 'GPE', 384)\n"
     ]
    }
   ],
   "source": [
    "test_doc = nlp(u\"Rami Eid is studying at Stony Brook University in New York\")\n",
    "for ent in test_doc.ents:\n",
    "    print((ent, ent.label_, ent.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 名词短语提取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_doc = nlp(u'Natural language processing (NLP) deals with the application of computational models to text or speech data. Application areas within NLP include automatic (machine) translation between languages; dialogue systems, which allow a human to interact with a machine using natural language; and information extraction, where the goal is to transform unstructured text into structured (database) representations that can be searched and browsed in flexible ways. NLP technologies are having a dramatic impact on the way people interact with computers, on the way people interact with each other through the use of language, and on the way people access the vast amount of linguistic data now in electronic form. From a scientific viewpoint, NLP involves fundamental questions of how to structure formal models (for example statistical models) of natural language phenomena, and of how to design algorithms that implement these models.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing\n",
      "the application\n",
      "computational models\n",
      "text\n",
      "speech data\n",
      "Application areas\n",
      "NLP\n",
      "automatic (machine) translation\n",
      "languages\n",
      "dialogue systems\n",
      "a human\n",
      "a machine\n",
      "natural language\n",
      "information extraction\n",
      "the goal\n",
      "unstructured text\n",
      "database\n",
      "flexible ways\n",
      "NLP technologies\n",
      "a dramatic impact\n",
      "the way\n",
      "people\n",
      "computers\n",
      "the way\n",
      "people\n",
      "the use\n",
      "language\n",
      "the way\n",
      "people\n",
      "the vast amount\n",
      "linguistic data\n",
      "electronic form\n",
      "a scientific viewpoint\n",
      "NLP\n",
      "fundamental questions\n",
      "formal models\n",
      "example\n",
      "natural language phenomena\n",
      "algorithms\n",
      "these models\n"
     ]
    }
   ],
   "source": [
    "for np in test_doc.noun_chunks:\n",
    "    print(np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于词向量计算两个单词的相似度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple and orange are similar. Boots and hippos aren't."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc = nlp(u\"Apple and orange are similar. Boots and hippos aren't.\")\n",
    "test_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n"
     ]
    }
   ],
   "source": [
    "apple = test_doc[0]\n",
    "print(apple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orange\n"
     ]
    }
   ],
   "source": [
    "orange = test_doc[2]\n",
    "print(orange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hippos\n"
     ]
    }
   ],
   "source": [
    "hippos = test_doc[8]\n",
    "print(hippos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boots\n"
     ]
    }
   ],
   "source": [
    "boots = test_doc[6]\n",
    "print(boots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raymond\\anaconda3\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35227782"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple.similarity(orange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raymond\\anaconda3\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34843963"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boots.similarity(hippos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 现在试试Spacy自带的词嵌入模型\n",
    "对于英文来说，词嵌入模型位于 en_core_web_lg 模型下，需要提前下载好。lg比sm大很多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拿\"minister\"测试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.2239e-01  3.8982e-01  6.4522e-01  8.7596e-02  4.0262e-01 -4.1253e-01\n",
      "  1.3804e-01 -4.0226e-01 -3.0679e-01  3.6520e+00 -6.1745e-01 -2.4114e-01\n",
      "  1.7488e-01 -2.5995e-01 -3.8512e-01 -1.3747e-01 -3.7446e-01 -8.0867e-01\n",
      "  2.8081e-01  2.9735e-01  1.7901e-01 -3.4726e-02  7.2466e-02 -5.2111e-01\n",
      "  7.1858e-02  1.5913e-01 -6.0877e-01  1.6604e-01 -9.3809e-02  2.0030e-01\n",
      " -5.0653e-01 -1.4978e-01  1.7742e-01  3.2996e-02 -2.1082e-01 -6.0442e-02\n",
      " -9.6639e-02 -4.6054e-01 -7.1622e-02 -1.4829e-01  5.1362e-01 -3.7840e-01\n",
      " -3.2035e-01 -1.1593e-01 -1.5887e-01  2.5999e-01  2.6821e-01  2.7429e-01\n",
      " -5.8973e-02 -1.0218e-01  6.6629e-03  3.5737e-01  3.1083e-01  4.7950e-01\n",
      "  4.4323e-01  8.0089e-03  6.4577e-02 -4.1851e-01  3.2589e-01 -6.0894e-01\n",
      " -3.5944e-01  1.9116e-01  1.5910e-02 -1.8912e-01  1.2646e-01 -9.6918e-03\n",
      " -6.5529e-01 -4.1851e-01  4.0244e-01 -6.7241e-01 -7.6219e-01  2.6207e-01\n",
      " -1.5607e+00  3.2982e-01 -4.1586e-01  3.4098e-01 -1.2571e-01 -1.2014e-01\n",
      "  1.3608e-02 -1.7894e-01  5.0916e-01 -2.8449e-01 -1.9519e-01  1.7161e-01\n",
      " -1.8038e-01 -3.7242e-01  2.8779e-01 -9.9446e-01  3.8110e-01 -3.6687e-01\n",
      "  6.7859e-01  4.1517e-01  1.4029e-04 -9.2324e-02  1.4499e-01 -6.3138e-01\n",
      "  8.5580e-02  9.8767e-02 -4.2732e-02 -5.1192e-01 -3.6008e-01  1.7807e-01\n",
      "  4.3106e-01 -2.7113e-01  2.6117e-01 -1.1093e+00 -5.3453e-02  1.2964e-01\n",
      "  7.2043e-02 -2.9840e-01 -3.0373e-01  1.2479e-01 -6.2262e-01  3.1790e-01\n",
      " -5.0850e-02 -3.4046e-01 -7.0588e-01  7.3111e-02 -9.7412e-02  1.5489e-01\n",
      " -1.7524e-01 -9.3642e-02 -4.5105e-01  3.4972e-01  2.2643e-01  3.3525e-01\n",
      "  2.0722e-01 -5.2710e-01 -3.6449e-01  6.1503e-02 -2.8858e-01  2.8356e-01\n",
      "  1.2859e-01 -3.3722e-01  9.9695e-02  5.4493e-01  3.4306e-01  6.4749e-01\n",
      " -1.3339e-01 -3.0286e-01 -7.0783e-02  1.6607e-01 -5.3108e-01 -1.1629e-01\n",
      "  1.8794e-01  8.7658e-02  8.2277e-02 -5.9183e-01 -1.3002e+00 -3.1180e-01\n",
      " -4.5598e-02  2.9376e-01 -1.9878e-01 -4.1425e-01  3.5388e-01  2.6559e-01\n",
      "  3.2310e-01  1.6575e-01  1.7211e-01  1.8798e-01  2.0010e-01 -1.7585e-01\n",
      " -1.4383e-01  4.6441e-01 -3.5426e-01  3.5655e-02  2.1650e-01 -6.9591e-01\n",
      " -1.9097e-03  3.5148e-01 -4.4031e-01  2.5784e-02 -1.6795e-01  6.7284e-01\n",
      "  9.0581e-02 -1.8994e-01  5.4949e-01  1.4926e-01  7.2222e-01 -3.3370e-01\n",
      " -5.1958e-01  3.2437e-01  1.9644e-01 -1.5863e-01  1.9083e-03  5.1186e-01\n",
      " -9.5662e-02  2.1656e-02 -1.3161e-01 -1.1805e-01  1.6575e-01  2.9505e-01\n",
      "  4.9018e-01 -4.2977e-01 -1.5993e-01 -3.6753e-01  8.7457e-02 -6.8308e-02\n",
      " -1.5331e-01 -2.7103e-01 -5.4915e-01  9.1917e-01  4.2635e-01 -5.2601e-01\n",
      "  8.4366e-01  5.7226e-02  1.9534e-01 -3.8182e-01 -9.0527e-02  4.5610e-02\n",
      " -9.6872e-03 -6.0501e-01 -2.8681e-01  2.8389e-01  6.2697e-01 -1.0516e-01\n",
      " -4.8453e-01 -3.2606e-01 -5.7180e-01  4.4597e-01 -7.7640e-02  3.0929e-01\n",
      "  1.2633e-01  1.1981e+00  6.9421e-01  3.7257e-01 -4.8151e-02  8.7035e-02\n",
      " -5.7236e-01  4.3714e-01  6.7161e-02  4.1036e-01 -2.5125e-01 -6.1381e-01\n",
      "  9.6459e-03 -5.2952e-01 -2.5677e-01  2.1411e-01 -2.6532e-01  5.5811e-02\n",
      "  8.7852e-02  1.2621e-01  3.5266e-01 -5.6351e-01 -3.5930e-01 -1.3401e-01\n",
      "  7.7801e-01 -2.5249e-01  2.0385e-01 -6.5584e-01 -4.9989e-02  8.7359e-01\n",
      "  4.5170e-01 -2.5920e-01  9.2309e-01  3.6927e-01  4.7212e-01 -4.0808e-01\n",
      " -6.7676e-01  2.8296e-01  1.1870e-01  2.5123e-01  6.3988e-02  3.8518e-01\n",
      " -4.5629e-01 -4.9095e-01 -2.9056e-01  1.1609e-01 -1.4937e-01 -3.6742e-01\n",
      "  1.9663e-01  4.5344e-01 -1.3246e-01  3.2582e-01 -3.9982e-01  1.8979e-01\n",
      "  3.0114e-01  7.4952e-01  7.7731e-02  1.2773e-01  5.0207e-02  3.8849e-02\n",
      "  1.5883e-01  1.9287e-01 -4.3273e-01 -1.1075e-01  2.8002e-03  6.2109e-01\n",
      " -6.8976e-01  1.1181e-01  4.9622e-01  8.5923e-02  2.5591e-01 -1.4410e-01\n",
      "  1.6128e-01  4.0757e-01  2.0046e-01 -1.0036e-01  6.1331e-01 -5.2357e-01]\n"
     ]
    }
   ],
   "source": [
    "print(nlp.vocab['minister'].vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog = nlp.vocab[\"dog\"]\n",
    "cat = nlp.vocab[\"cat\"]\n",
    "apple = nlp.vocab[\"apple\"]\n",
    "orange = nlp.vocab[\"orange\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x150091ed480>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，cat是个spacy内部的一种格式的对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56189173"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple.similarity(orange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80168545"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.similarity(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28213844"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.similarity(apple)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
